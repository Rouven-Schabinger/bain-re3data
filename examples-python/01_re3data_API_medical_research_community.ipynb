{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case 1: Identify and collect information about repositories catering to the medical research community (Python)\n",
    "\n",
    "> This notebook is based on the examples written in `R` from Dorothea Strecker's [examples-r/01_re3data_API_medical_research_community.ipynb](https://github.com/re3data/using_the_re3data_API/blob/main/examples-r/01_re3data_API_medical_research_community.ipynb).  \n",
    "> Adapted in `Python` by Heinz-Alexander Fütterer.\n",
    "\n",
    "Medical researchers are looking for a suitable repository to deposit their data. They require a repository catering to medical research that offers data upload and assigns DOIs to datasets.\n",
    "\n",
    "Repositories meeting these specifications can be identified via the re3data API. The API also provides the option to retrieve further information about these repositories, such as the name of the repository or a description.\n",
    "\n",
    "### Step 1: load packages\n",
    "\n",
    "The package `httpx` includes the HTTP method GET, which will be used to request data from the re3data API. Responses from the redata API are returned in XML. `lxml` includes functions for working with XML, for example parsing or extracting content of specific elements. The `pandas` library is used for storing the responses in a tabular data structure (i.e. a `DataFrame`).\n",
    "\n",
    "If necessary, install the packages before loading them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpx in /home/codespace/.local/lib/python3.12/site-packages (0.28.1)\n",
      "Collecting lxml\n",
      "  Downloading lxml-5.3.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from httpx) (4.7.0)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/codespace/.local/lib/python3.12/site-packages (from httpx) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx) (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->httpx) (4.12.2)\n",
      "Downloading lxml-5.3.1-cp312-cp312-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: lxml\n",
      "Successfully installed lxml-5.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install httpx lxml pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import httpx\n",
    "import pandas\n",
    "from lxml import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: define query parameters\n",
    "\n",
    "Information on individual repositories can be extracted using the re3data ID. Therefore, re3data IDs of repositories with the desired characteristics need to be identified first.\n",
    "\n",
    "The re3data API allows querying via the endpoint **/api/beta/repositories**. Parameters that can be queried are listed in the [re3data API documentaion](https://www.re3data.org/api/doc). For more information on re3data metadata, including descriptions of available elements and controlled vocabularies, please refer to the documentation of the [re3data Metadata Schema](https://doi.org/10.2312/re3.006) (the API uses version 2.2 of the re3data Metadata Schema).  \n",
    "The query below returns re3data IDs of repositories meeting the following conditions:\n",
    "\n",
    "* **\"subjects[]\" = \"205 Medicine\"** The repository caters to the subject *Medicine*, notation 205 in the DFG Subject Classification, the subject classification used by re3data.\n",
    "* **\"dataUploads[]\"=\"open\"** The repository allows data upload.\n",
    "* **\"pidSystems[]\"=\"DOI\"** The repository assigns DOIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "re3data_query = {\n",
    "    \"subjects[]\": \"205 Medicine\",\n",
    "    \"dataUploads[]\": \"open\",\n",
    "    \"pidSystems[]\": \"DOI\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: obtain URLs for further API queries\n",
    "\n",
    "The query parameters defined in the previous step can then be passed to the re3data API using `httpx.get()`.\n",
    "\n",
    "The XML response is parsed using `html.fromstring()`. XML elements or attributes can be identified using XPath syntax. The response from the re3data API includes URLs for further queries to the **/api/beta/repository** endpoint. These URLs can be identified with a simple XPath expression. All attributes matching the XPath syntax are identified with `.xpath()`.\n",
    "\n",
    "The three functions are nested in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.re3data.org/api/beta/repository/r3d100012823',\n",
       " 'https://www.re3data.org/api/beta/repository/r3d100012815',\n",
       " 'https://www.re3data.org/api/beta/repository/r3d100010261',\n",
       " 'https://www.re3data.org/api/beta/repository/r3d100010493']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = \"https://www.re3data.org/api/beta/repositories\"\n",
    "\n",
    "re3data_response = httpx.get(URL, params=re3data_query)\n",
    "urls = html.fromstring(re3data_response.content).xpath(\"//@href\")\n",
    "\n",
    "urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: define what information about the repositories should be requested\n",
    "\n",
    "The function `extract_repository_info()` defined in the following code block extracts the content of specific XML elements and attributes. This function will be used to extract the specified information from responses of the re3data API. Its basic structure is similar to the process of extracting the URLs outlined in step 3 above.\n",
    "The XPath expressions defined here will extract the re3data IDs, names, URLs, and descriptions of the repositories. Results are stored in a dictionary that can be processed later.\n",
    "\n",
    "Depending on specific use cases, this function can be adapted to extract a different set of elements and attributes. For an overview of the metadata re3data offers, please refer to the documentation of the [re3data Metadata Schema](https://doi.org/10.2312/re3.006) (the API uses version 2.2 of the re3data Metadata Schema).\n",
    "    \n",
    "Please note that in version 2.2 of the re3data Metadata Schema, the elements mentioned here have occurences of 1 or 0-1, meaning that for each repository, they occur once at most. For information on how to deal with elements that can occur multiple times, please refer to other examples for using the re3data API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import typing\n",
    "\n",
    "def extract_repository_info(xml_content: typing.Union[str, etree._Element]) -> typing.Dict[str, typing.Optional[str]]:\n",
    "    \"\"\"Extracts repository metadata from an XML string or element.\n",
    "\n",
    "    Args:\n",
    "        xml_content: The XML content as a string or an lxml element.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the repository metadata.\n",
    "    \"\"\"\n",
    "    # If xml_content is an lxml element, convert it to a string\n",
    "    if isinstance(xml_content, etree._Element):\n",
    "        xml_content = etree.tostring(xml_content, encoding=\"unicode\")\n",
    "\n",
    "    # Parse the XML content\n",
    "    repository_metadata_xml = etree.fromstring(xml_content)\n",
    "\n",
    "    # Define the namespace\n",
    "    namespaces = {\"r3d\": \"http://www.re3data.org/schema/2-2\"}\n",
    "\n",
    "    # Extract metadata using XPath with namespaces\n",
    "    re3data_id = repository_metadata_xml.xpath(\"//r3d:re3data.orgidentifier/text()\", namespaces=namespaces)\n",
    "    name = repository_metadata_xml.xpath(\"//r3d:repositoryname/text()\", namespaces=namespaces)\n",
    "    url = repository_metadata_xml.xpath(\"//r3d:repositoryurl/text()\", namespaces=namespaces)\n",
    "    description = repository_metadata_xml.xpath(\"//r3d:description/text()\", namespaces=namespaces)\n",
    "\n",
    "    \n",
    "\n",
    "    # Return the extracted metadata\n",
    "    return {\n",
    "        \"re3data_id\": re3data_id[0] if re3data_id else None,\n",
    "        \"name\": name[0] if name else None,\n",
    "        \"url\": url[0] if url else None,\n",
    "        \"description\": description[0] if description else None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: gather detailed information about repositories\n",
    "\n",
    "After preparing the list of URLs and the extracting function, these components can be put together. The code block below iterates through the list of URLs using a for-loop. For each repository, data is requested from the re3data API using `.get()` from a `httpx.Client`. The XML response is parsed with `html.fromstring()` before `extract_repository_info()` is called. The results are then appended to `results_list`.\n",
    "\n",
    "`repository_info` is a container for storing results of the API query. The DataFrame has four columns corresponding to names of the list items defined by `extract_repository_info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "with httpx.Client() as client:\n",
    "    for url in urls:\n",
    "        repository_metadata_response = client.get(url)\n",
    "        repository_metadata_xml = html.fromstring(repository_metadata_response.content)\n",
    "        results.append(extract_repository_info(repository_metadata_xml))\n",
    "\n",
    "repository_info = pandas.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Look at the results\n",
    "\n",
    "Results are now stored in `repository_info`. They can be inspected using `.head()`, visualized or stored locally with `.to_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>re3data_id</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r3d100012823</td>\n",
       "      <td>Vivli</td>\n",
       "      <td>https://vivli.org/</td>\n",
       "      <td>Vivli is a non-profit organization working to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r3d100012815</td>\n",
       "      <td>UNB Libraries Dataverse Research Data Repository</td>\n",
       "      <td>https://dataverse.lib.unb.ca/</td>\n",
       "      <td>UNB Dataverse is repository for research data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r3d100010261</td>\n",
       "      <td>National Addiction &amp; HIV Data Archive Program</td>\n",
       "      <td>https://www.icpsr.umich.edu/web/pages/NAHDAP/i...</td>\n",
       "      <td>NAHDAP acquires, preserves and disseminates da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r3d100010493</td>\n",
       "      <td>Sikt Research Data Archive</td>\n",
       "      <td>https://sikt.no/en/find-data</td>\n",
       "      <td>Sikt archives research data on people and soci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     re3data_id                                              name  \\\n",
       "0  r3d100012823                                             Vivli   \n",
       "1  r3d100012815  UNB Libraries Dataverse Research Data Repository   \n",
       "2  r3d100010261     National Addiction & HIV Data Archive Program   \n",
       "3  r3d100010493                        Sikt Research Data Archive   \n",
       "\n",
       "                                                 url  \\\n",
       "0                                 https://vivli.org/   \n",
       "1                      https://dataverse.lib.unb.ca/   \n",
       "2  https://www.icpsr.umich.edu/web/pages/NAHDAP/i...   \n",
       "3                       https://sikt.no/en/find-data   \n",
       "\n",
       "                                         description  \n",
       "0  Vivli is a non-profit organization working to ...  \n",
       "1  UNB Dataverse is repository for research data ...  \n",
       "2  NAHDAP acquires, preserves and disseminates da...  \n",
       "3  Sikt archives research data on people and soci...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repository_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
